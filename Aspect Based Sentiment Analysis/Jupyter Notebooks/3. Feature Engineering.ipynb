{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##########################################\n",
    "# --- Importing the standard libraries ---\n",
    "##########################################\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc_ID</th>\n",
       "      <th>Review</th>\n",
       "      <th>CLEANLINESS</th>\n",
       "      <th>ROOM</th>\n",
       "      <th>SERVICE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>VALUE</th>\n",
       "      <th>OVERALL_RATING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>china_beijing_holiday_inn_central_plaza</td>\n",
       "      <td>[\"Just about everything about this hotel is fa...</td>\n",
       "      <td>4.786</td>\n",
       "      <td>4.631</td>\n",
       "      <td>4.733</td>\n",
       "      <td>3.553</td>\n",
       "      <td>4.699</td>\n",
       "      <td>4.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>china_beijing_hilton_beijing_wangfujing</td>\n",
       "      <td>['An excellent hotel, with the best room I hav...</td>\n",
       "      <td>4.810</td>\n",
       "      <td>4.845</td>\n",
       "      <td>4.759</td>\n",
       "      <td>4.828</td>\n",
       "      <td>4.517</td>\n",
       "      <td>4.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>china_beijing_hotel_g</td>\n",
       "      <td>['It was chic, everyone was friendly, service ...</td>\n",
       "      <td>4.769</td>\n",
       "      <td>4.750</td>\n",
       "      <td>4.577</td>\n",
       "      <td>4.375</td>\n",
       "      <td>4.654</td>\n",
       "      <td>4.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>china_beijing_the_regent_beijing</td>\n",
       "      <td>[\"My parents and I stayed here during their vi...</td>\n",
       "      <td>4.625</td>\n",
       "      <td>4.812</td>\n",
       "      <td>4.438</td>\n",
       "      <td>4.646</td>\n",
       "      <td>4.531</td>\n",
       "      <td>4.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>china_beijing_the_st_regis_beijing</td>\n",
       "      <td>['this hotel was fantastic. rooms were lovely....</td>\n",
       "      <td>4.846</td>\n",
       "      <td>4.646</td>\n",
       "      <td>4.615</td>\n",
       "      <td>4.492</td>\n",
       "      <td>4.185</td>\n",
       "      <td>4.557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Doc_ID  \\\n",
       "0  china_beijing_holiday_inn_central_plaza   \n",
       "1  china_beijing_hilton_beijing_wangfujing   \n",
       "2                    china_beijing_hotel_g   \n",
       "3         china_beijing_the_regent_beijing   \n",
       "4       china_beijing_the_st_regis_beijing   \n",
       "\n",
       "                                              Review  CLEANLINESS   ROOM  \\\n",
       "0  [\"Just about everything about this hotel is fa...        4.786  4.631   \n",
       "1  ['An excellent hotel, with the best room I hav...        4.810  4.845   \n",
       "2  ['It was chic, everyone was friendly, service ...        4.769  4.750   \n",
       "3  [\"My parents and I stayed here during their vi...        4.625  4.812   \n",
       "4  ['this hotel was fantastic. rooms were lovely....        4.846  4.646   \n",
       "\n",
       "   SERVICE  LOCATION  VALUE  OVERALL_RATING  \n",
       "0    4.733     3.553  4.699           4.481  \n",
       "1    4.759     4.828  4.517           4.752  \n",
       "2    4.577     4.375  4.654           4.625  \n",
       "3    4.438     4.646  4.531           4.610  \n",
       "4    4.615     4.492  4.185           4.557  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################\n",
    "# --- Importing the Dataset ---\n",
    "################################\n",
    "\n",
    "data = pd.read_csv('../Prepared Data/Hotel_Reviews.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Features (Using Stopwords Removal and Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "# --- Function to Extract the Reviews ---\n",
    "#########################################\n",
    "\n",
    "##> Description\n",
    "# Loops through all the reviews\n",
    "# Apply's the following things:-\n",
    "#        1. Removing all the symbols, dots, commas, etc. which are not required as features\n",
    "#        2. Converting the alphabets to lower case\n",
    "#        3. Splits the review into list of words\n",
    "#        4. Removes the stopwords like pronouns, determiners, etc.\n",
    "#        5. Appends all the clean reviews into a corpus list\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(data):\n",
    "    corpus = []\n",
    "    \n",
    "    for i in range(0, len(data)):\n",
    "        \n",
    "        review = re.sub('[^a-zA-Z]', ' ', data['Review'][i])    \n",
    "        review = review.lower()                                 \n",
    "        review = review.split()                                 \n",
    "        \n",
    "        lmtzr = WordNetLemmatizer()\n",
    "        review = [lmtzr.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "        \n",
    "        review = ' '.join(review)\n",
    "        \n",
    "        corpus.append(review)\n",
    "    return corpus\n",
    "\n",
    "\n",
    "corpus = extract_features(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# --- Save our Corpus ---\n",
    "#########################\n",
    "\n",
    "with open('../Corpus/corpus.txt', 'a') as f:\n",
    "    for line in corpus:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Features (Using Parts of Speech (POS) Tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################\n",
    "# --- Parts of Speech (POS) Tagging ---\n",
    "#######################################\n",
    "##> Extracting only Nouns and Adjectives which are the most describing words\n",
    "# Appends a list of of tuples containing only 'NN' or 'JJ' into tag_list\n",
    "\n",
    "def pos_extract(blob):\n",
    "    tags_list = []\n",
    "    for i in blob.tags:\n",
    "        if (i[1] == 'NN') or (i[1] == 'JJ'):\n",
    "            tags_list.append(i)\n",
    "    return tags_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################################\n",
    "# --- Function to Extract the Reviews ---\n",
    "#########################################\n",
    "\n",
    "##> Description\n",
    "# Loops through all the reviews\n",
    "# Apply's the following things:-\n",
    "#        1. Extract the POS tags for each review\n",
    "#        2. Storing the nouns and adjectives into a review list\n",
    "#        3. Appends all the extracted reviews into a corpus list\n",
    "\n",
    "\n",
    "\n",
    "def extract_features_2(data):\n",
    "    corpus = []\n",
    "    \n",
    "    for i in range(0, len(data)):\n",
    "        \n",
    "        review = []\n",
    "        \n",
    "        blob = TextBlob(data['Review'][i])\n",
    "        \n",
    "        NN_JJ_tags = pos_extract(blob)\n",
    "        \n",
    "        for word in NN_JJ_tags:\n",
    "            review.append(word[0])\n",
    "        \n",
    "        review = ' '.join(review)\n",
    "        \n",
    "        corpus.append(review)\n",
    "        \n",
    "    return corpus\n",
    "\n",
    "\n",
    "corpus = extract_features_2(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# --- Save our Corpus ---\n",
    "#########################\n",
    "\n",
    "with open('../Corpus/corpus2.txt', 'a') as f:\n",
    "    for line in corpus:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Features (Using Noun Phrases Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################\n",
    "# --- Noun Phrases Extraction ---\n",
    "#################################\n",
    "##> Noun Phrase consists of (Det)(Adj)NN(PP)\n",
    "\n",
    "\n",
    "def extract_features_3(data):\n",
    "    corpus = []\n",
    "    \n",
    "    for i in range(0, len(data)):\n",
    "        \n",
    "        review = []\n",
    "        \n",
    "        blob = TextBlob(data['Review'][i])\n",
    "        \n",
    "        noun_phrase_list = list(blob.noun_phrases)\n",
    "        \n",
    "        for word in noun_phrase_list:\n",
    "            review.append(word)\n",
    "        \n",
    "        review = ' '.join(review)\n",
    "        \n",
    "        corpus.append(review)\n",
    "        \n",
    "    return corpus\n",
    "\n",
    "\n",
    "corpus = extract_features_3(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# --- Save our Corpus ---\n",
    "#########################\n",
    "\n",
    "with open('../Corpus/corpus3.txt', 'a') as f:\n",
    "    for line in corpus:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the Features (Using Bi-Grams and N-Grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "# --- Bi-Grams and N-Grams ---\n",
    "##############################\n",
    "\n",
    "# bi_grams = blob.ngrams(n=2)\n",
    "# n_grams = blob.ngrams(n=3)\n",
    "\n",
    "def extract_features_4(data, n):\n",
    "    corpus = []\n",
    "    \n",
    "    for i in range(0, len(data)):\n",
    "        \n",
    "        review = []\n",
    "        \n",
    "        blob = TextBlob(data['Review'][i])\n",
    "        \n",
    "        bi_grams = blob.ngrams(n=n)\n",
    "        \n",
    "        for word in bi_grams:\n",
    "            word = ' '.join(word)\n",
    "            review.append(word)\n",
    "        \n",
    "        review = ' '.join(review)\n",
    "        \n",
    "        corpus.append(review)\n",
    "        \n",
    "    return corpus\n",
    "\n",
    "\n",
    "\n",
    "corpus = extract_features_4(data, n=2)                # For Bi-Grams\n",
    "# corpus = extract_features_4(data, n=3)                # For Tri-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#########################\n",
    "# --- Save our Corpus ---\n",
    "#########################\n",
    "\n",
    "with open('../Corpus/corpus4.txt', 'a') as f:\n",
    "    for line in corpus:\n",
    "        f.write(line)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
